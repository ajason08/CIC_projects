{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class NgramAnalyzer:\n",
    "    \n",
    "    gram_dict = {}    \n",
    "    total_unigrams = 0\n",
    "    total_bigrams = 0\n",
    "    total_trigrams = 0\n",
    "        \n",
    "    def __init__(self, file_url):\n",
    "        self.file_url = file_url\n",
    "    \n",
    "    def ngram_creator(self, wordlist,n):            \n",
    "            ngrams = []\n",
    "            for i in range(len(wordlist)):        \n",
    "                ngram = wordlist[i:i+n]\n",
    "                if len(ngram) == n:\n",
    "                    ngrams.append(ngram)\n",
    "            return ngrams\n",
    "    \n",
    "    def run(self):        \n",
    "        wordlist = []\n",
    "        with open(self.file_url) as myfile: \n",
    "            # reading line by line avoid out-of-memory issues when working with large files.\n",
    "            for line in myfile:\n",
    "                #print(\"-----------------\",line)\n",
    "\n",
    "                # capturing last words for get n-grams between lines\n",
    "                try: last_word = wordlist[-1:] \n",
    "                except: last_word = []\n",
    "                try: last2_words = wordlist[-2:] \n",
    "                except: last2_word = []        \n",
    "\n",
    "                # collecting ngrams by calling n_gram_creator\n",
    "                wordlist = line.split()          \n",
    "                unigrams = self.ngram_creator(wordlist, 1)\n",
    "                bigrams = self.ngram_creator(last_word + wordlist, 2)\n",
    "                trigrams = self.ngram_creator(last2_words + wordlist, 3)\n",
    "                ngrams = unigrams + bigrams + trigrams                \n",
    "                \n",
    "                self.total_unigrams += len(unigrams)\n",
    "                self.total_bigrams += len(bigrams)\n",
    "                self.total_trigrams += len(trigrams)\n",
    "\n",
    "                # save/storing at dictionary\n",
    "                for gram in ngrams:            \n",
    "                    gram = \" \".join(gram)\n",
    "                    try:                \n",
    "                        self.gram_dict[gram] += 1\n",
    "                        #print(word, gram_dict[word])\n",
    "                    except:\n",
    "                        self.gram_dict[gram] = 1\n",
    "                        #print(\"---\",word)\n",
    "\n",
    "        \n",
    "    def run_pmi(self,ocurrences_threshold, score_threshold=0):        \n",
    "        # ocurrences_threshold: minimum number of occurrences a n-gram should have in each of its word to be considered\n",
    "        # score_threshold: minimum pm_score a n-gram should have to be considered\n",
    "        \n",
    "        # controlling whether ngram information is available\n",
    "        try:\n",
    "            assert len(self.gram_dict)>0, \"it is empty, you first should to call run method\"\n",
    "        except:\n",
    "            print (\"******* internally it called run method\")\n",
    "            self.run()\n",
    "        \n",
    "        bigrams_scores = {}\n",
    "        trigrams_scores = {}\n",
    "        for gram in self.gram_dict:\n",
    "            \n",
    "            # filter out unigrams and ngrams do not overcome the ocurrences_threshold\n",
    "            gram_list = gram.split()\n",
    "            if len(gram_list)<2: continue\n",
    "            if not all([self.gram_dict[word]>ocurrences_threshold for word in gram_list]): continue                        \n",
    "            \n",
    "            # compute probabilities\n",
    "            total_ngrams= self.total_bigrams if len(gram_list)==2 else self.total_trigrams\n",
    "            gram_count = self.gram_dict[gram]/total_ngrams\n",
    "            gram_list_counts = [self.gram_dict[word]/self.total_unigrams for word in gram_list]\n",
    "            \n",
    "            # compute pmi score e.g. pmi_sc = P(w1,w2,w3)/P(w1)P(w2)P(w3)\n",
    "            mult_ind_words= 1\n",
    "            for word_count in gram_list_counts:\n",
    "                mult_ind_words = mult_ind_words*word_count            \n",
    "            coocurrence_score=log2(gram_count/mult_ind_words)\n",
    "            \n",
    "            # filter n-grams based on pmi_score\n",
    "            if coocurrence_score < score_threshold: continue\n",
    "            \n",
    "            # reporting results in different dictionaries\n",
    "            if len(gram_list)==2: bigrams_scores[gram] = coocurrence_score\n",
    "            if len(gram_list)==3: trigrams_scores[gram] = coocurrence_score\n",
    "        return bigrams_scores, trigrams_scores                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demostration: dictionary of ngrams frequencies\n",
      "The 6149\n",
      "Project 205\n",
      "Gutenberg 78\n",
      "EBook 5\n",
      "of 39169\n",
      "Adventures 2\n",
      "Sherlock 95\n",
      "Holmes 198\n",
      "The Project 13\n",
      "Project Gutenberg 74\n",
      "Gutenberg EBook 5\n",
      "... \n",
      "A total of 1386757 different ngrams where found.\n"
     ]
    }
   ],
   "source": [
    "#################### Main\n",
    "\n",
    "# Read file, extract ngrams (unigrams, bigrams and trigrams) and save them in a dictionary variable of an object\n",
    "url = \"C:/my_temp_files/peter_norvig_file.txt\"\n",
    "my_ngram_analyzer = NgramAnalyzer(url)\n",
    "my_ngram_analyzer.run()\n",
    "\n",
    "# demostration: dictionary of ngrams frequencies\n",
    "dictionary = my_ngram_analyzer.gram_dict\n",
    "\n",
    "print(\"Demostration: dictionary of ngrams frequencies\")\n",
    "\n",
    "for i, gram in enumerate(dictionary):    \n",
    "    print(gram, dictionary[gram])\n",
    "    if i == 10: break\n",
    "print (\"... \\nA total of\", len(dictionary), \"different ngrams where found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstration: bigrams and trigrams pmi_scores. Showing for threshold = 100\n",
      "                     ngram  pmi_score\n",
      "1496  Project Gutenberg-tm  12.412818\n",
      "2792   [Illustration: FIG.  11.980397\n",
      "1504              New York  11.195880\n",
      "815          United States  11.008437\n",
      "3748         Princess Mary  10.598099\n",
      "4238        Princess Mary,  10.484811\n",
      "7                   OF THE  10.212413\n",
      "2916           vessel wall  10.181655\n",
      "2740           takes place  10.133388\n",
      "36                \"My dear  10.047668\n",
      "2932         lymph vessels  10.020624\n",
      "347            Mr. Holmes,  10.007705\n",
      "2884          lymph glands   9.943219\n",
      "4925      presented itself   9.879802\n",
      "3766         drawing room,   9.861783\n",
      "3051            soft parts   9.849331\n",
      "2946    treatment consists   9.825658\n",
      "3760         drawing room.   9.823951\n",
      "1737           paper money   9.784738\n",
      "2901          takes place,   9.781307\n",
      "2958          cold abscess   9.766711\n",
      "1110         several times   9.762912\n",
      "3203      observed chiefly   9.750122\n",
      "1993  federal Constitution   9.665227\n",
      "2803           giving rise   9.646646\n",
      "1515               AND THE   9.633758\n",
      "7018         Countess Mary   9.592795\n",
      "2817             give rise   9.573907\n",
      "749            anyone else   9.567365\n",
      "1544           New England   9.520427\n",
      "...                    ...        ...\n",
      "2458            having got   5.004524\n",
      "3906          Anatole kept   5.004379\n",
      "6116             away. And   5.003772\n",
      "413           some strange   5.003687\n",
      "7256            girl known   5.003634\n",
      "1276            few things   5.003455\n",
      "2464       call themselves   5.003427\n",
      "2326         under federal   5.003261\n",
      "4858        going straight   5.003261\n",
      "916               call for   5.002746\n",
      "4269        young Nicholas   5.002682\n",
      "3717           disease of,   5.002682\n",
      "1578          _The English   5.002641\n",
      "3479             _The deep   5.002641\n",
      "235          another. \"But   5.002599\n",
      "3063            great pain   5.002585\n",
      "6545            Moscow nor   5.002241\n",
      "6479             go again,   5.002186\n",
      "5584             half past   5.002144\n",
      "2655       foreign country   5.002144\n",
      "1655             hand. For   5.001813\n",
      "2058           For members   5.001813\n",
      "2349           South that,   5.001152\n",
      "1160                due to   5.001109\n",
      "1236       appeared before   5.000929\n",
      "5285          himself. \"It   5.000780\n",
      "7081             said. \"It   5.000780\n",
      "7218          means growth   5.000615\n",
      "5092             pass here   5.000532\n",
      "2986          part pressed   5.000202\n",
      "\n",
      "[7377 rows x 2 columns]\n",
      "                               ngram  pmi_score\n",
      "38366      full Project Gutenberg-tm  21.162340\n",
      "53080              joint lesions in,  20.709259\n",
      "48555        considerable size (Fig.  19.990678\n",
      "128968      Nicholas, Countess Mary,  19.984849\n",
      "38480                          | | |  19.953637\n",
      "16739                 My friend rose  19.888008\n",
      "72314          easily attack instead  19.820999\n",
      "38383      Project Gutenberg-tm work  19.781995\n",
      "40666           making firm pressure  19.731989\n",
      "124349           away, twenty voices  19.726658\n",
      "47820        vessels slowly increase  19.712354\n",
      "41792           dead portion produce  19.705022\n",
      "103213                 An hour later  19.689811\n",
      "44870           slowly growing forms  19.651142\n",
      "38520            showing changes due  19.598977\n",
      "13661             door. My attention  19.531020\n",
      "71238      question presented itself  19.525819\n",
      "69226     immediately smiling again,  19.520824\n",
      "132318              hard terms doubt  19.517080\n",
      "68780            low opinion changed  19.508013\n",
      "52038          takes place, although  19.503273\n",
      "48070         change which, although  19.502516\n",
      "43634      secondary lesions similar  19.478030\n",
      "11566                   so. Now turn  19.477855\n",
      "123131       running away, described  19.450603\n",
      "48071       which, although attended  19.445031\n",
      "82969     French, immediately seized  19.442125\n",
      "104029       repeated again, smiling  19.432166\n",
      "38362   Gutenberg-tm name associated  19.423340\n",
      "132362           slowly tears horses  19.419242\n",
      "...                              ...        ...\n",
      "127527                 taking up the   5.002450\n",
      "54087                   father to be   5.002391\n",
      "96825              expected from the   5.002360\n",
      "31211              officers from the   5.002360\n",
      "108162               from the right,   5.002360\n",
      "115576             Russians from the   5.002360\n",
      "56231                   out from her   5.002324\n",
      "73301                  other who was   5.002264\n",
      "52208                     in a joint   5.001997\n",
      "50567                   is acute and   5.001804\n",
      "6928                which marked the   5.001777\n",
      "79951                on which Prince   5.001752\n",
      "49892                   tissue of an   5.001707\n",
      "61143                 the two people   5.001696\n",
      "2450                    I thought he   5.001601\n",
      "126414                    wish it to   5.001553\n",
      "66592                and answered at   5.001369\n",
      "53761                        up as a   5.001099\n",
      "117479            especially that he   5.000877\n",
      "118533                came to Prince   5.000771\n",
      "17142                    he was soon   5.000585\n",
      "88410                   and then, on   5.000548\n",
      "48098             when the condition   5.000436\n",
      "47524             the condition when   5.000436\n",
      "30739                   all the free   5.000411\n",
      "35713                into the states   5.000367\n",
      "5701                     had an only   5.000364\n",
      "47459                   or even with   5.000308\n",
      "53284                the question he   5.000106\n",
      "62764               the regiment but   5.000062\n",
      "\n",
      "[132370 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# extract ngrams (bigrams and trigrams) based on occurences_threshold and pmi_score_threshold\n",
    "occurences_threshold = 100\n",
    "score_threshold = 5\n",
    "bigram_pmi_scores, trigram_pmi_scores = my_ngram_analyzer.run_pmi(occurences_threshold, score_threshold)\n",
    "\n",
    "\n",
    "# demonstrarion: bigram and trigrams pmi_scores\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "def gram_dataframe(ngram_dictionary, pmi_threshold = 0):\n",
    "    ngrams_keys = list(ngram_dictionary.keys())\n",
    "    ngrams_values = list(ngram_dictionary.values())\n",
    "    data = {\"ngram\":ngrams_keys, \"pmi_score\": ngrams_values}\n",
    "    sorted_df = df.from_dict(data).sort_values(by='pmi_score', ascending=False)\n",
    "    return sorted_df\n",
    "\n",
    "print(\"demonstration: bigrams and trigrams pmi_scores. Showing for threshold = 100\")\n",
    "print(gram_dataframe(bigram_pmi_scores))\n",
    "print(gram_dataframe(trigram_pmi_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis:\n",
      "- A min_ocurrence_threshold = 100 seems to work pretty good for extract collocation of bigrams.\n",
      "- However at extracting collocation of trigrams a min_ocurrence_threshold = 360 leads to better results.\n",
      "- Posterior data cleaning like (case converter, remove punctuation, POS filtering, etc) can increase the gap for discriminate collocation and keywords.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis = \"\"\"\n",
    "Analysis:\n",
    "- A min_ocurrence_threshold = 100 seems to work pretty good for extract collocation of bigrams.\n",
    "- However at extracting collocation of trigrams a min_ocurrence_threshold = 360 leads to better results.\n",
    "- Posterior data cleaning like (case converter, remove punctuation, POS filtering, etc) can increase the gap for discriminate collocation and keywords.\n",
    "\"\"\"\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
