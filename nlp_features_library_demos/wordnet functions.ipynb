{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def all_definitions(word,pos=\"n\"):\n",
    "    w= wn.synsets(word,pos)\t\n",
    "    for num in range(len(w)):\n",
    "        num=num+1\n",
    "        synset_sp = f'{word}.{pos}.{num}'\n",
    "        s= wn.synset(synset_sp)\n",
    "        print(num, s.definition())\n",
    "\n",
    "def all_def_examp(word,pos=\"n\"):\n",
    "    w= wn.synsets(word,pos)\t\n",
    "    for num in range(len(w)):\n",
    "        num=num+1\n",
    "        synset_sp = f'{word}.{pos}.{num}'\n",
    "        s= wn.synset(synset_sp)\n",
    "        print(num, s.definition())\n",
    "        print(s.examples())\n",
    "\n",
    "def synset_from_sense_key(sense_key):\n",
    "    sense_key_regex = r\"(.*)\\%(.*):(.*):(.*):(.*):(.*)\"\n",
    "    synset_types = {1:'n', 2:'v', 3:'a', 4:'r', 5:'s'}\n",
    "    lemma, ss_type, lex_num, lex_id, head_word, head_id = re.match(sense_key_regex, sense_key).groups()\n",
    "    ss_idx = '.'.join([lemma, synset_types[int(ss_type)], lex_id])\n",
    "    return wn.synset(ss_idx)\n",
    "wn.get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Synset('have.v.01')\n",
      "definition: have or possess, either in a concrete or an abstract sense\n",
      "lemas: [Lemma('have.v.01.have'), Lemma('have.v.01.have_got'), Lemma('have.v.01.hold')]\n",
      "\n",
      "--------- Synset('have.v.02')\n",
      "definition: have as a feature\n",
      "lemas: [Lemma('have.v.02.have'), Lemma('have.v.02.feature')]\n",
      "\n",
      "--------- Synset('experience.v.03')\n",
      "definition: go through (mental or physical states or experiences)\n",
      "lemas: [Lemma('experience.v.03.experience'), Lemma('experience.v.03.receive'), Lemma('experience.v.03.have'), Lemma('experience.v.03.get')]\n",
      "hyperonyms [Lemma('undergo.v.01.undergo')]\n",
      "\n",
      "--------- Synset('own.v.01')\n",
      "definition: have ownership or possession of\n",
      "lemas: [Lemma('own.v.01.own'), Lemma('own.v.01.have'), Lemma('own.v.01.possess')]\n",
      "\n",
      "--------- Synset('get.v.03')\n",
      "definition: cause to move; cause to be in a certain position or condition\n",
      "lemas: [Lemma('get.v.03.get'), Lemma('get.v.03.let'), Lemma('get.v.03.have')]\n",
      "hyperonyms [Lemma('make.v.02.make'), Lemma('make.v.02.get')]\n",
      "\n",
      "--------- Synset('consume.v.02')\n",
      "definition: serve oneself to, or consume regularly\n",
      "lemas: [Lemma('consume.v.02.consume'), Lemma('consume.v.02.ingest'), Lemma('consume.v.02.take_in'), Lemma('consume.v.02.take'), Lemma('consume.v.02.have')]\n",
      "\n",
      "--------- Synset('have.v.07')\n",
      "definition: have a personal or business relationship with someone\n",
      "lemas: [Lemma('have.v.07.have')]\n",
      "hyperonyms [Lemma('interact.v.01.interact')]\n",
      "\n",
      "--------- Synset('hold.v.03')\n",
      "definition: organize or be responsible for\n",
      "lemas: [Lemma('hold.v.03.hold'), Lemma('hold.v.03.throw'), Lemma('hold.v.03.have'), Lemma('hold.v.03.make'), Lemma('hold.v.03.give')]\n",
      "hyperonyms [Lemma('direct.v.04.direct')]\n",
      "\n",
      "--------- Synset('have.v.09')\n",
      "definition: have left\n",
      "lemas: [Lemma('have.v.09.have')]\n",
      "\n",
      "--------- Synset('have.v.10')\n",
      "definition: be confronted with\n",
      "lemas: [Lemma('have.v.10.have')]\n",
      "\n",
      "--------- Synset('have.v.11')\n",
      "definition: undergo\n",
      "lemas: [Lemma('have.v.11.have'), Lemma('have.v.11.experience')]\n",
      "hyperonyms [Lemma('change.v.02.change')]\n",
      "\n",
      "--------- Synset('have.v.12')\n",
      "definition: suffer from; be ill with\n",
      "lemas: [Lemma('have.v.12.have')]\n",
      "hyperonyms [Lemma('suffer.v.06.suffer'), Lemma('suffer.v.06.hurt')]\n",
      "\n",
      "--------- Synset('induce.v.02')\n",
      "definition: cause to do; cause to act in a specified manner\n",
      "lemas: [Lemma('induce.v.02.induce'), Lemma('induce.v.02.stimulate'), Lemma('induce.v.02.cause'), Lemma('induce.v.02.have'), Lemma('induce.v.02.get'), Lemma('induce.v.02.make')]\n",
      "\n",
      "--------- Synset('accept.v.02')\n",
      "definition: receive willingly something given or offered\n",
      "lemas: [Lemma('accept.v.02.accept'), Lemma('accept.v.02.take'), Lemma('accept.v.02.have')]\n",
      "hyperonyms [Lemma('get.v.01.get'), Lemma('get.v.01.acquire')]\n",
      "\n",
      "--------- Synset('receive.v.01')\n",
      "definition: get something; come into possession of\n",
      "lemas: [Lemma('receive.v.01.receive'), Lemma('receive.v.01.have')]\n",
      "hyperonyms [Lemma('get.v.01.get'), Lemma('get.v.01.acquire')]\n",
      "\n",
      "--------- Synset('suffer.v.02')\n",
      "definition: undergo (as of injuries and illnesses)\n",
      "lemas: [Lemma('suffer.v.02.suffer'), Lemma('suffer.v.02.sustain'), Lemma('suffer.v.02.have'), Lemma('suffer.v.02.get')]\n",
      "hyperonyms [Lemma('experience.v.03.experience'), Lemma('experience.v.03.receive'), Lemma('experience.v.03.have'), Lemma('experience.v.03.get')]\n",
      "\n",
      "--------- Synset('have.v.17')\n",
      "definition: achieve a point or goal\n",
      "lemas: [Lemma('have.v.17.have'), Lemma('have.v.17.get'), Lemma('have.v.17.make')]\n",
      "hyperonyms [Lemma('score.v.01.score'), Lemma('score.v.01.hit'), Lemma('score.v.01.tally'), Lemma('score.v.01.rack_up')]\n",
      "\n",
      "--------- Synset('give_birth.v.01')\n",
      "definition: cause to be born\n",
      "lemas: [Lemma('give_birth.v.01.give_birth'), Lemma('give_birth.v.01.deliver'), Lemma('give_birth.v.01.bear'), Lemma('give_birth.v.01.birth'), Lemma('give_birth.v.01.have')]\n",
      "hyperonyms [Lemma('produce.v.01.produce'), Lemma('produce.v.01.bring_forth')]\n",
      "\n",
      "--------- Synset('take.v.35')\n",
      "definition: have sex with; archaic use\n",
      "lemas: [Lemma('take.v.35.take'), Lemma('take.v.35.have')]\n",
      "hyperonyms [Lemma('sleep_together.v.01.sleep_together'), Lemma('sleep_together.v.01.roll_in_the_hay'), Lemma('sleep_together.v.01.love'), Lemma('sleep_together.v.01.make_out'), Lemma('sleep_together.v.01.make_love'), Lemma('sleep_together.v.01.sleep_with'), Lemma('sleep_together.v.01.get_laid'), Lemma('sleep_together.v.01.have_sex'), Lemma('sleep_together.v.01.know'), Lemma('sleep_together.v.01.do_it'), Lemma('sleep_together.v.01.be_intimate'), Lemma('sleep_together.v.01.have_intercourse'), Lemma('sleep_together.v.01.have_it_away'), Lemma('sleep_together.v.01.have_it_off'), Lemma('sleep_together.v.01.screw'), Lemma('sleep_together.v.01.fuck'), Lemma('sleep_together.v.01.jazz'), Lemma('sleep_together.v.01.eff'), Lemma('sleep_together.v.01.hump'), Lemma('sleep_together.v.01.lie_with'), Lemma('sleep_together.v.01.bed'), Lemma('sleep_together.v.01.have_a_go_at_it'), Lemma('sleep_together.v.01.bang'), Lemma('sleep_together.v.01.get_it_on'), Lemma('sleep_together.v.01.bonk')]\n"
     ]
    }
   ],
   "source": [
    "w= wn.synsets(\"have\",\"v\")\n",
    "for sense in w:     \n",
    "     print (\"\\n---------\",sense)\n",
    "     print (\"definition:\",sense.definition())\n",
    "     print (\"lemas:\",sense.lemmas())\n",
    "     for hyper in sense.hypernyms():             \n",
    "             print (\"hyperonyms\", hyper.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('own.v.01.own'), Lemma('own.v.01.have'), Lemma('own.v.01.possess')]\n"
     ]
    }
   ],
   "source": [
    "word = \"have\"\n",
    "pos = \"v\"\n",
    "num= 4\n",
    "synset_sp = f'{word}.{pos}.{num}'\n",
    "s= wn.synset(synset_sp)\n",
    "print(s.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a man who lives on the frontier\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_def_examp(\"frontiersman\",pos=\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "WordNetError",
     "evalue": "line '43 n 0000 ~ 07999699 n 0000 | a general concept formed by extracting common features from specific examples  \\n': invalid literal for int() with base 10: 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_synset_from_pos_and_line\u001b[0;34m(self, pos, data_file_line)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;31m# determine the lexicographer file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0mlexname_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_next_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m             \u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lexname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lexnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlexname_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'n'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ff9a8a400838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mof2ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'00002342n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mof2ss\u001b[0;34m(self, of)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mof2ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;34m''' take an id and return the synsets '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset_from_pos_and_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mss2of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36msynset_from_pos_and_offset\u001b[0;34m(self, pos, offset)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mdata_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0mdata_file_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m         \u001b[0msynset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_synset_from_pos_and_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_synset_offset_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_synset_from_pos_and_line\u001b[0;34m(self, pos, data_file_line)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;31m# raise a more informative error with line text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWordNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'line %r: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_file_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;31m# set sense keys for Lemma objects - note that this has to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWordNetError\u001b[0m: line '43 n 0000 ~ 07999699 n 0000 | a general concept formed by extracting common features from specific examples  \\n': invalid literal for int() with base 10: 'n'"
     ]
    }
   ],
   "source": [
    "wn.of2ss('00002342n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
