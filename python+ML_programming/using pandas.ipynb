{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-ignite\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7b/1da69e5fdcb70e8f40ff3955516550207d5f5c81b428a5056510e72c60c5/pytorch_ignite-0.2.0-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 820kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/jason/anaconda3/envs/pytorch_env/lib/python3.7/site-packages (from pytorch-ignite) (1.0.1.post2)\n",
      "Installing collected packages: pytorch-ignite\n",
      "Successfully installed pytorch-ignite-0.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_path= \"/home/jason/nlpws/patents/\"\n",
    "\n",
    "patent_df = pd.read_csv(my_path+'patents_nouns.csv',delimiter=',')\n",
    "patent_df.columns = [\"id_doc\",\"category\",\"concepts\",\"words\"]\n",
    "\n",
    "train_df = pd.read_csv(my_path+'train.csv',delimiter=',', header=None, names= [\"id_doc\", 'category'])\n",
    "dev_df = pd.read_csv(my_path+'dev.csv',delimiter=',', header=None, names= [\"id_doc\", 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id_doc category                                           concepts  \\\n",
      "5       1001        G  bn:00000488n#bn:00007436n#bn:00021551n#bn:0007...   \n",
      "6       1002        A  bn:00000489n#bn:00001698n#bn:00064167n#bn:0000...   \n",
      "15      1010        A                          bn:00006835n#bn:00032726n   \n",
      "24      1019        G  bn:00000488n#bn:00071525n#bn:15125301n#bn:0007...   \n",
      "27      1021        G  bn:00000488n#bn:00054625n#bn:00069078n#bn:0005...   \n",
      "34      1028        G  bn:00000488n#bn:01641329n#bn:15125301n#bn:0000...   \n",
      "37      1030        G  bn:00000488n#bn:00061119n#bn:01325950n#bn:0007...   \n",
      "41      1034        A  bn:00000490n#bn:00036926n#bn:00044489n#bn:0001...   \n",
      "47       104        C  bn:00000488n#bn:00058201n#bn:00018101n#bn:0387...   \n",
      "51      1043        A  bn:16998653n#bn:15125301n#bn:00019934n#bn:0001...   \n",
      "58       105        C  bn:00000488n#bn:15882913n#bn:00054550n#bn:0005...   \n",
      "59      1050        E  bn:00000488n#bn:00015784n#bn:00063534n#bn:0001...   \n",
      "75      1065        A  bn:00000488n#bn:01641329n#bn:00054625n#bn:0002...   \n",
      "77      1067        G  bn:00000488n#bn:00021551n#bn:00034265n#bn:0353...   \n",
      "84      1073        A  bn:00000488n#bn:00021551n#bn:00036686n#bn:0357...   \n",
      "92      1080        A  bn:00063445n#bn:00064855n#bn:00063445n#bn:0002...   \n",
      "95      1083        C  bn:01134517n#bn:00334558n#bn:03534544n#bn:0113...   \n",
      "96      1084        G  bn:00000075n#bn:00000488n#bn:00026638n#bn:0002...   \n",
      "101     1089        G  bn:00000488n#bn:00027489n#bn:00045970n#bn:0004...   \n",
      "104     1091        A  bn:00000489n#bn:17348611n#bn:15310311n#bn:0002...   \n",
      "110     1097        A  bn:00000488n#bn:00021551n#bn:00030158n#bn:0005...   \n",
      "116     1101        A  bn:00000488n#bn:00021551n#bn:00054625n#bn:0333...   \n",
      "117     1102        A  bn:00000488n#bn:00016768n#bn:00070959n#bn:1378...   \n",
      "118     1103        C  bn:00000488n#bn:00027489n#bn:00021398n#bn:0005...   \n",
      "136      112        G  bn:00000488n#bn:00027489n#bn:00032512n#bn:0002...   \n",
      "143     1126        A  bn:00005929n#bn:00041418n#bn:00079373n#bn:0004...   \n",
      "152     1134        C  bn:00000488n#bn:00021551n#bn:00020872n#bn:0004...   \n",
      "156     1138        A  bn:00044024n#bn:00046376n#bn:00136241n#bn:0002...   \n",
      "166     1147        F  bn:00723168n#bn:03157745n#bn:00005095n#bn:0006...   \n",
      "172     1152        A  bn:00000490n#bn:00007436n#bn:00026716n#bn:0002...   \n",
      "...      ...      ...                                                ...   \n",
      "4810     855        C  bn:00000488n#bn:00018101n#bn:00018110n#bn:0020...   \n",
      "4816     860        B  bn:00000488n#bn:00000205n#bn:01682932n#bn:0004...   \n",
      "4820     864        B  bn:00000488n#bn:00021551n#bn:00026716n#bn:0003...   \n",
      "4825     869        G  bn:00000488n#bn:00077880n#bn:00077585n#bn:0384...   \n",
      "4826      87        E  bn:00000488n#bn:00022872n#bn:00034004n#bn:0002...   \n",
      "4828     871        G  bn:00000488n#bn:00026631n#bn:00026716n#bn:0002...   \n",
      "4829     872        F  bn:00000488n#bn:00027471n#bn:00015784n#bn:0001...   \n",
      "4831     874        E  bn:00000488n#bn:00016338n#bn:00021902n#bn:1360...   \n",
      "4835     878        G  bn:00000489n#bn:00076341n#bn:00054548n#bn:0002...   \n",
      "4836     879        A  bn:00000488n#bn:00408977n#bn:00012974n#bn:0000...   \n",
      "4840     882        A  bn:00000488n#bn:00020872n#bn:00749648n#bn:0007...   \n",
      "4850     891        C  bn:00000488n#bn:00021551n#bn:00031732n#bn:0005...   \n",
      "4852     893        G  bn:00000488n#bn:00035767n#bn:00026638n#bn:0162...   \n",
      "4862     901        C  bn:00000490n#bn:03599833n#bn:00034225n#bn:0077...   \n",
      "4863     902        F  bn:00000706n#bn:00021915n#bn:00062569n#bn:0002...   \n",
      "4867     906        C  bn:00000488n#bn:00061887n#bn:00066295n#bn:0005...   \n",
      "4878     916        B  bn:00000488n#bn:00053801n#bn:00741141n#bn:0001...   \n",
      "4888     925        A  bn:00000488n#bn:00076843n#bn:00013142n#bn:0007...   \n",
      "4889     926        A  bn:00000488n#bn:00036491n#bn:00056727n#bn:0005...   \n",
      "4900     936        E  bn:00000488n#bn:00070190n#bn:00046934n#bn:0007...   \n",
      "4917     951        A  bn:00000488n#bn:00021551n#bn:00058252n#bn:0000...   \n",
      "4918     952        B  bn:00000488n#bn:00006857n#bn:00464458n#bn:0046...   \n",
      "4922     956        B  bn:00000488n#bn:00032099n#bn:00030333n#bn:0007...   \n",
      "4925     959        E  bn:00000488n#bn:00024779n#bn:00008690n#bn:0000...   \n",
      "4929     962        A  bn:00000488n#bn:00057778n#bn:00059991n#bn:0003...   \n",
      "4930     963        C  bn:00000488n#bn:00021551n#bn:00008467n#bn:0002...   \n",
      "4938     970        A  bn:00000488n#bn:00007436n#bn:00079517n#bn:0002...   \n",
      "4948      98        G  bn:00000488n#bn:00008713n#bn:00059141n#bn:0001...   \n",
      "4955     987        A  bn:00000488n#bn:03639670n#bn:00027489n#bn:0000...   \n",
      "4965     996        H  bn:00000488n#bn:03639670n#bn:00027489n#bn:0003...   \n",
      "\n",
      "                                                  words  \n",
      "5     ABSTRACT#embodiments#invention#techniques#radi...  \n",
      "6     ABSTRACT#aerosol#preparation#assembly#entrainm...  \n",
      "15                                           NA#failure  \n",
      "24    ABSTRACT#signal#system#tool#people#behaviour#r...  \n",
      "27    ABSTRACT#method#sample#material#material#densi...  \n",
      "34    Abstract#method#system#authenticity#consumer#c...  \n",
      "37    ABSTRACT#payment#payment system#system#method#...  \n",
      "41    ABSTRACT#fusion#plate#bone#material#interface#...  \n",
      "47    ABSTRACT#Novel#compounds#substituents#carbon#c...  \n",
      "51    METHOD#SYSTEM#MYSTERY#BONUS#PLACE#BASE#GAME#RE...  \n",
      "58    Abstract#hard metal#metal#material#method#comp...  \n",
      "59    ABSTRACT#head#pool#broom#microfibre#cloth#dirt...  \n",
      "75    ABSTRACT#ABSTRACT Method#Method#soil#soil#wate...  \n",
      "77    ABSTRACT#invention#field#smart water#water#wat...  \n",
      "84    Abstract#invention#fruit#fruit picker#picker#r...  \n",
      "92    POLYSACCHARIDE#PROTEIN#POLYSACCHARIDE#CROSS#HY...  \n",
      "95    amt#Interwoven#DCC#AMT#docx#ABSTRACT#A method#...  \n",
      "96    II#Abstract#sensing element#element#detection#...  \n",
      "101   ABSTRACT#disclosure#image#information#block#pi...  \n",
      "104   ABSTRACT#Disclosed#medical devices#devices#tho...  \n",
      "110   Abstract#invention#receptacle#medical instrume...  \n",
      "116   ABSTRACT#invention#method#broad spectrum#spect...  \n",
      "117   ABSTRACT#catheter#sheath#introducer#hub#sheath...  \n",
      "118   Abstract#disclosure#compositions#methods#tissu...  \n",
      "136   ABSTRACT#DISCLOSURE#eye#device#lens#enclosure#...  \n",
      "143   GRAPHICAL#GRAPHICAL USER INTERFACE#USER#USER I...  \n",
      "152   ABSTRACT#invention#combination#treatment#PD#ax...  \n",
      "156   HIGH#PENETRATION#PRODRUG#COMPOSITIONS#PHARMACE...  \n",
      "166   INTERNATIONAL#INTERNATIONAL APPLICATION#APPLIC...  \n",
      "172   ABSTRACT#embodiment#device#portion#object#conc...  \n",
      "...                                                 ...  \n",
      "4810  ABSTRACT#compounds#formula#formula 1#glutamina...  \n",
      "4816  ABSTRACT#abalone#diving knife#knife#gauge#abal...  \n",
      "4820  ABSTRACT#invention#device#exploration#ocean#sp...  \n",
      "4825  Abstract#TRADING#TOOLS#ELECTRONIC#ELECTRONIC T...  \n",
      "4826  Abstract#corrosion#member#core#member#axis#axi...  \n",
      "4828  ABSTRACT#detection#device#state#electrical cir...  \n",
      "4829  ABSTRACT#discharge#head#features#deflection#co...  \n",
      "4831  ABSTRACT#clip#connection#building component#co...  \n",
      "4835  ABSTRACT#Techniques#metadata#code#code generat...  \n",
      "4836  ABSTRACT#humidification#breathing apparatus#ap...  \n",
      "4840  ABSTRACT#COMBINATION#COMBINATION THERAPY#THERA...  \n",
      "4850  Abstract#invention#procaine#procaine hydrochlo...  \n",
      "4852  ABSTRACT#force#sensor#environmental effects#ef...  \n",
      "4862  ABSTRACT#Perforin#fibroblasts#microglia#macrop...  \n",
      "4863  FITTING#JOINING#PIPE#ELEMENTS#ABSTRACT#pipe#el...  \n",
      "4867  Abstract#Pharmaceutical#raw materials#material...  \n",
      "4878  ABSTRACT#material#material handling#chute#chut...  \n",
      "4888  ABSTRACT#therapy#delivery#delivery system#syst...  \n",
      "4889  ABSTRACT#novelty#nail#nail trimming#tool#metal...  \n",
      "4900  ABSTRACT#section#installation#service#supply#s...  \n",
      "4917  ABSTRACT#invention#nucleic acids#acids#mutants...  \n",
      "4918  ABSTRACT#cobalt#Fischer Tropsch#Fischer Tropsc...  \n",
      "4922  ABSTRACT#example#elevator#system#pathway#pathw...  \n",
      "4925  ABSTRACT#cylinder#barrel#barrel#cam#cam#recess...  \n",
      "4929  Abstract#nitric oxide#oxide#gas#treatment#dise...  \n",
      "4930  ABSTRACT#invention#prevention#treatment#comple...  \n",
      "4938  ABSTRACT#embodiments#valves#leaflets#leaflet#s...  \n",
      "4948  ABSTRACT#barrier#operator#feature#enhancement#...  \n",
      "4955  ABSTRACT#ABSTRACT OF THE DISCLOSURE#DISCLOSURE...  \n",
      "4965  ABSTRACT#ABSTRACT OF THE DISCLOSURE#DISCLOSURE...  \n",
      "\n",
      "[795 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "train_id =train_df['id_doc'].values.tolist()\n",
    "dev_id =dev_df['id_doc'].values.tolist()\n",
    "#print(dev_id)\n",
    "\n",
    "train_set = patent_df[patent_df[\"id_doc\"].isin(train_id)]\n",
    "dev_set = patent_df[patent_df[\"id_doc\"].isin(dev_id)]\n",
    "#print(train_set.shape,dev_set.shape)\n",
    "print(dev_set)\n",
    "\n",
    "train_set.to_csv(my_path+\"train_set.csv\", sep='\\t',index=False)\n",
    "dev_set.to_csv(my_path+\"dev_set.csv\", sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import string\n",
    "def tokenizer(s):\n",
    "#     table = str.maketrans({k: None for k in string.punctuation})\n",
    "#     return [w.translate(table) for w in s[1:-1].split()]\n",
    "    s = s.replace('#', ' ')\n",
    "    return [w for w in s.split()]\n",
    "def tokenizer1(s):\n",
    "    return [w for w in s.split('#')] #if w.endswith('n')]\n",
    "\n",
    "\n",
    "from torchtext import data as ttdata\n",
    "\n",
    "# words, concepts and categories\n",
    "txt_field = ttdata.Field(sequential=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
    "conc_field = ttdata.Field(sequential=True, tokenize=tokenizer1, include_lengths=True, use_vocab=True)\n",
    "label_field = ttdata.Field(sequential=False, use_vocab=True, pad_token=None, unk_token=None)\n",
    "\n",
    "\n",
    "tr_dev_fields = [('id_doc', None), ('category', label_field), ('concepts', conc_field), ('words', txt_field)]\n",
    "train, val = ttdata.TabularDataset.splits(path=my_path, format='tsv', train='train_set.csv', validation='dev_set.csv', fields=tr_dev_fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_doc\tcategory\tconcepts\twords\r\n",
      "1001\tG\tbn:00000488n#bn:00007436n#bn:00021551n#bn:00076341n#bn:01831700n#bn:00021485n#bn:00041418n#bn:00079373n#bn:00047088n#bn:00047087n#bn:00005095n#bn:00007436n#bn:01831700n#bn:00021485n#bn:00047730n#bn:00051760n#bn:00017120n#bn:01831700n#bn:00021485n#bn:01831700n#bn:00021485n#bn:00076341n#bn:00007436n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00060767n#bn:00047730n#bn:13713593n#bn:00047730n#bn:00040336n#bn:00062349n#bn:00021485n#bn:00027675n#bn:00062349n#bn:00021485n#bn:02690436n#bn:01831700n#bn:00021485n#bn:00005095n#bn:01105477n#bn:00054390n#bn:00031025n#bn:00061135n#bn:03303891n#bn:00034265n#bn:00021551n#bn:00021551n#bn:00064213n#bn:00021485n#bn:03632398n#bn:00059228n#bn:00041418n#bn:00079373n#bn:00047088n#bn:00047087n#bn:00021551n#bn:00059228n#bn:00026512n#bn:00007781n#bn:00021551n#bn:00079373n#bn:00047088n#bn:00047087n#bn:00021464n#bn:00021464n#bn:00005095n#bn:00020945n#bn:00079373n#bn:00047088n#bn:00047087n#bn:00077585n#bn:00079373n#bn:00016401n#bn:00005095n#bn:00028831n#bn:00021485n#bn:00021485n#bn:00051508n#bn:00020945n#bn:00020945n#bn:00021475n#bn:00028018n#bn:00028018n#bn:00005095n#bn:00020945n#bn:00060158n#bn:03197621n#bn:03229350n#bn:00081546n#bn:00081559n#bn:00005095n#bn:00017029n#bn:00073631n#bn:00005095n#bn:00009291n#bn:00028831n#bn:00021485n#bn:00081292n#bn:00005095n#bn:00009291n#bn:00028831n#bn:00021485n#bn:00024529n#bn:00000753n#bn:00024529n#bn:00081292n#bn:00024529n#bn:00005088n#bn:00026716n#bn:00025965n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00016397n#bn:00024529n#bn:00047730n#bn:00065158n#bn:00021485n#bn:00079373n#bn:00024529n#bn:00027749n#bn:00021485n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00024529n#bn:00027749n#bn:00064093n#bn:00021485n#bn:01732102n#bn:00047730n#bn:02690436n#bn:01831700n#bn:00021485n#bn:00021485n#bn:00018661n#bn:00027041n#bn:00009291n#bn:00028831n#bn:00021485n#bn:01831700n#bn:00021485n#bn:00005095n#bn:00026107n#bn:01831700n#bn:00021485n#bn:00017761n#bn:00021485n#bn:00079373n#bn:00054390n#bn:16111634n#bn:00005927n#bn:00073184n#bn:00000937n#bn:00075094n#bn:16111634n#bn:00005927n#bn:00005939n#bn:00026512n#bn:00037658n#bn:00020452n#bn:00740869n#bn:00048653n#bn:16111634n#bn:00005927n#bn:00062297n#bn:16111634n#bn:00005927n#bn:00156996n#bn:00156996n#bn:00046516n#bn:00005927n#bn:00075142n#bn:00021551n#bn:00006382n#bn:00021551n#bn:00054625n#bn:00030270n#bn:00026716n#bn:00077726n#bn:00075373n#bn:01831700n#bn:00021485n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:00047730n#bn:00017120n#bn:00051760n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00003268n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00003268n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:00015178n#bn:03843242n#bn:00017120n#bn:00051760n#bn:01831700n#bn:00021485n#bn:00021485n#bn:00015178n#bn:03843242n#bn:01831700n#bn:00021485n#bn:00046848n#bn:00046848n#bn:00075599n#bn:00077726n#bn:00075373n#bn:00067367n#bn:00046848n#bn:03402745n#bn:00026650n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00046848n#bn:00027352n#bn:00003268n#bn:03402745n#bn:00026650n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00046848n#bn:00027352n#bn:00003268n#bn:00006382n#bn:00021551n#bn:00021464n#bn:00054149n#bn:00021464n#bn:00021492n#bn:00062759n#bn:00014395n#bn:01831700n#bn:00021485n#bn:00021464n#bn:00021492n#bn:00062759n#bn:00070696n#bn:00027356n#bn:01831700n#bn:00021485n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00017120n#bn:00051760n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00003268n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00003268n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:00015178n#bn:03843242n#bn:00017120n#bn:00051760n#bn:01831700n#bn:00021485n#bn:00021485n#bn:00015178n#bn:03843242n#bn:01831700n#bn:00021485n#bn:00046848n#bn:00046848n#bn:00075599n#bn:00077726n#bn:00075373n#bn:00067367n#bn:00046848n#bn:03402745n#bn:00026650n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00046848n#bn:00027352n#bn:00003268n#bn:03402745n#bn:00026650n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00027675n#bn:00047730n#bn:00018661n#bn:00023853n#bn:00046848n#bn:00027352n#bn:00003268n#bn:00054625n#bn:00045771n#bn:01831700n#bn:00021485n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00045771n#bn:00067367n#bn:00079373n#bn:01541423n#bn:00046848n#bn:01831700n#bn:00021485n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00017120n#bn:00051760n#bn:00017120n#bn:00051760n#bn:00062704n#bn:00045771n#bn:00027675n#bn:00064673n#bn:00045771n#bn:01831700n#bn:00021485n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00067367n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00062349n#bn:00021485n#bn:00070696n#bn:00062349n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00051760n#bn:00021464n#bn:00054149n#bn:00021464n#bn:00021492n#bn:00062759n#bn:00014395n#bn:01831700n#bn:00021485n#bn:00021464n#bn:00062759n#bn:00070696n#bn:00027356n#bn:00045771n#bn:01831700n#bn:00021485n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00045771n#bn:00067367n#bn:00079373n#bn:01541423n#bn:00046848n#bn:01831700n#bn:00021485n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00017120n#bn:00051760n#bn:00017120n#bn:00051760n#bn:00062704n#bn:00045771n#bn:00027675n#bn:00064673n#bn:00045771n#bn:00021485n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00063110n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00067367n#bn:00079373n#bn:01541423n#bn:00046848n#bn:00062349n#bn:00021485n#bn:00070696n#bn:00062349n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00051760n#bn:00007436n#bn:00021551n#bn:00076341n#bn:01831700n#bn:00021485n#bn:00041418n#bn:00079373n#bn:00047088n#bn:00047087n#bn:00005095n#bn:00007436n#bn:01831700n#bn:00021485n#bn:00047730n#bn:00051760n#bn:00017120n#bn:01831700n#bn:00021485n#bn:01831700n#bn:00021485n#bn:00076341n#bn:00007436n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00060767n#bn:00047730n#bn:13713593n#bn:00047730n#bn:00040336n#bn:00062349n#bn:00021485n#bn:00027675n#bn:00062349n#bn:00021485n#bn:00002088n#bn:00047730n#bn:00051760n#bn:00064072n#bn:00047730n#bn:00007436n#bn:00007436n#bn:00027749n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00047730n#bn:00064072n#bn:00047730n#bn:00064072n#bn:00007436n#bn:00003268n#bn:00004117n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00079373n#bn:00024529n#bn:00077733n#bn:00060767n#bn:00003268n#bn:00004117n#bn:00018661n#bn:00046848n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00007436n#bn:00003268n#bn:00004117n#bn:00064072n#bn:00047730n#bn:00064072n#bn:00047730n#bn:00023853n#bn:00064072n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00000986n#bn:00018661n#bn:00000986n#bn:00018661n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00007436n#bn:00044086n#bn:00060767n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00007436n#bn:00021485n#bn:01732102n#bn:00047730n#bn:00045771n#bn:00060767n#bn:00045771n#bn:00044086n#bn:00007436n#bn:00051108n#bn:00017120n#bn:01831700n#bn:00021485n#bn:00021485n#bn:01732102n#bn:00047730n\tABSTRACT#embodiments#invention#techniques#radial menus#menus#graphical user interfaces#user#user interfaces#interfaces#application#embodiments#radial menus#menus#items#location#center#radial menu#menu#radial menu#menu#techniques#embodiments#menu#menu items#items#region#item#selectability#item#gestures#sub#menus#display#sub#menu#RADIAL#RADIAL MENUS#MENUS#APPLICATION#Incorporated#reference#entirety#PCT#WO#FIELD#INVENTION#invention#presentation#menu#toolbar#options#graphical user interface#user#user interface#interface#invention#options#form#BACKGROUND#INVENTION#User#User interfaces#interfaces#computer#computer applications#applications#commands#user#user interface#interface#tools#user#instance#applications#drop down menus#menus#menus#lists#commands#commands#file#document#document#application#commands#page#page break#break#word#word processing#application#cells#spreadsheet#application#drop#drop down menus#menus#window#application#drop#drop down menus#menus#cursor#controller#cursor#window#cursor#control#device#level#menu#menu item#item#submenu#cursor#items#pull#menu#user#cursor#distance#menu#menu#menu item#item#cursor#distance#precision#menu#menu item#item#Radial#Radial menus#menus#menu#selections#difficulties#drop#drop down menus#menus#radial menus#menus#applications#need#radial menus#menus#features#menus#users#Reference#prior art#art#specification#acknowledgment#suggestion#prior art#art#art forms#forms#general knowledge#knowledge#knowledge in#jurisdiction#prior art#art#pieces#prior art#art#skilled person#skilled person in the art#person#art#SUMMARY#INVENTION#aspect#invention#method#electronic device#device#touch#surface#radial menu#menu#plurality#menu#menu items#items#menu#menu item#item#menu#item#center#location#menu#menu item#item#range#menu#menu item#item#menu#menu item#item#range#menu#menu item#item#menu#cancellation#button#center#location#radial menu#menu#menu#cancellation#button#radial menu#menu#input#input#swipe#touch#surface#response#input#accordance#determination#item#selection#criteria#menu#menu item#item#menu#menu item#item#display#menu#menu items#items#menu#menu item#item#display#item#selection#criteria#input#direction#range#accordance#determination#item#selection#criteria#menu#menu item#item#menu#menu item#item#display#menu#menu items#items#menu#menu item#item#display#item#selection#criteria#input#direction#range#aspect#invention#computer#medium#computer#computer program#program#processor#radial menu#menu#computer#computer program#program#sets#instructions#radial menu#menu#plurality#menu#menu items#items#menu#menu item#item#menu#menu item#item#center#location#menu#menu item#item#range#menu#menu item#item#menu#menu item#item#range#menu#menu item#item#menu#cancellation#button#center#location#radial menu#menu#menu#cancellation#button#radial menu#menu#input#input#swipe#touch#surface#response#input#accordance#determination#item#selection#criteria#menu#menu item#item#menu#menu item#item#display#menu#menu items#items#menu#menu item#item#display#item#selection#criteria#input#direction#range#accordance#determination#item#selection#criteria#menu#menu item#item#menu#menu item#item#display#menu#menu items#items#menu#menu item#item#display#item#selection#criteria#input#direction#range#method#icon#radial menu#menu#user#user input#input#icon#response#user#user input#input#radial menu#menu#plurality#menu#menu items#items#center#location#center#location#position#icon#display#screen#icon#radial menu#menu#user#user input#input#plurality#menu#menu items#items#response#user#user input#input#sub#menu#set#sub#menu#menu items#items#location#computer#medium#computer#computer program#program#processor#radial menu#menu#computer#program#sets#instructions#icon#radial menu#menu#user#user input#input#icon#response#user#user input#input#radial menu#menu#plurality#menu#menu items#items#center#location#center#location#position#icon#display#screen#icon#menu#user#user input#input#plurality#menu#menu items#items#response#user#user input#input#sub#menu#set#sub#menu#menu items#items#location#embodiments#invention#techniques#radial menus#menus#graphical user interfaces#user#user interfaces#interfaces#application#embodiments#radial menus#menus#items#location#center#radial menu#menu#radial menu#menu#techniques#embodiments#menu#menu items#items#region#item#selectability#item#gestures#sub#menus#display#sub#menu#arrangement#items#location#priorities#items#embodiments#embodiments#distance#menu#menu items#items#items#priority#items#priority#embodiments#range#angles#menu#menu item#item#user#cursor#touchscreen#region#range#angles#selection#input#menu#menu item#item#embodiments#range#angles#priority#items#priority#items#criteria#priorities#menu#menu items#items#frequency#selection#frequency#selection#menu#menu items#items#embodiments#highlight#region#menu#menu item#item#menu#menu item#item#embodiments#menu#menu item#item#icon#region#icon#highlight#embodiments#light#center#radial menu#menu#menu#menu item#item\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 /home/jason/nlpws/patents/dev_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7084720 [00:00<?, ?it/s]Skipping token b'7084720' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|█████████▉| 7080998/7084720 [03:00<00:00, 44550.98it/s]\n",
      "  0%|          | 0/55894 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 805/55894 [00:00<00:06, 8041.04it/s]\u001b[A\n",
      "  3%|▎         | 1740/55894 [00:00<00:06, 8391.26it/s]\u001b[A\n",
      "  5%|▍         | 2683/55894 [00:00<00:06, 8675.83it/s]\u001b[A\n",
      "  6%|▋         | 3566/55894 [00:00<00:06, 8720.01it/s]\u001b[A\n",
      "  8%|▊         | 4510/55894 [00:00<00:05, 8923.04it/s]\u001b[A\n",
      " 10%|▉         | 5450/55894 [00:00<00:05, 9059.61it/s]\u001b[A\n",
      " 11%|█▏        | 6393/55894 [00:00<00:05, 9167.11it/s]\u001b[A\n",
      " 13%|█▎        | 7344/55894 [00:00<00:05, 9265.47it/s]\u001b[A\n",
      " 15%|█▍        | 8297/55894 [00:00<00:05, 9341.82it/s]\u001b[A\n",
      " 17%|█▋        | 9250/55894 [00:01<00:04, 9397.08it/s]\u001b[A\n",
      " 18%|█▊        | 10202/55894 [00:01<00:04, 9433.28it/s]\u001b[A\n",
      " 20%|█▉        | 11147/55894 [00:01<00:04, 9437.98it/s]\u001b[A\n",
      " 22%|██▏       | 12100/55894 [00:01<00:04, 9462.80it/s]\u001b[A\n",
      " 23%|██▎       | 13052/55894 [00:01<00:04, 9479.10it/s]\u001b[A\n",
      " 25%|██▌       | 14014/55894 [00:01<00:04, 9519.70it/s]\u001b[A\n",
      " 27%|██▋       | 14963/55894 [00:01<00:04, 9183.18it/s]\u001b[A\n",
      " 28%|██▊       | 15882/55894 [00:01<00:04, 8787.15it/s]\u001b[A\n",
      " 30%|██▉       | 16765/55894 [00:01<00:04, 8586.66it/s]\u001b[A\n",
      " 32%|███▏      | 17720/55894 [00:01<00:04, 8853.71it/s]\u001b[A\n",
      " 33%|███▎      | 18683/55894 [00:02<00:04, 9072.81it/s]\u001b[A\n",
      " 35%|███▌      | 19636/55894 [00:02<00:03, 9205.28it/s]\u001b[A\n",
      " 37%|███▋      | 20563/55894 [00:02<00:03, 9221.50it/s]\u001b[A\n",
      " 38%|███▊      | 21488/55894 [00:02<00:03, 9077.50it/s]\u001b[A\n",
      " 40%|████      | 22399/55894 [00:02<00:03, 8470.27it/s]\u001b[A\n",
      " 42%|████▏     | 23283/55894 [00:02<00:03, 8575.39it/s]\u001b[A\n",
      " 43%|████▎     | 24222/55894 [00:02<00:03, 8804.45it/s]\u001b[A\n",
      " 45%|████▌     | 25162/55894 [00:02<00:03, 8972.51it/s]\u001b[A\n",
      " 47%|████▋     | 26106/55894 [00:02<00:03, 9106.35it/s]\u001b[A\n",
      " 48%|████▊     | 27042/55894 [00:02<00:03, 9180.23it/s]\u001b[A\n",
      " 50%|█████     | 27980/55894 [00:03<00:03, 9238.96it/s]\u001b[A\n",
      " 52%|█████▏    | 28924/55894 [00:03<00:02, 9296.41it/s]\u001b[A\n",
      " 53%|█████▎    | 29868/55894 [00:03<00:02, 9338.83it/s]\u001b[A\n",
      " 55%|█████▌    | 30815/55894 [00:03<00:02, 9376.91it/s]\u001b[A\n",
      " 57%|█████▋    | 31761/55894 [00:03<00:02, 9400.16it/s]\u001b[A\n",
      " 59%|█████▊    | 32702/55894 [00:03<00:02, 9364.32it/s]\u001b[A\n",
      " 60%|██████    | 33639/55894 [00:03<00:02, 9328.99it/s]\u001b[A\n",
      " 62%|██████▏   | 34573/55894 [00:03<00:02, 9286.75it/s]\u001b[A\n",
      " 64%|██████▎   | 35502/55894 [00:03<00:02, 9264.33it/s]\u001b[A\n",
      " 65%|██████▌   | 36429/55894 [00:03<00:02, 9260.62it/s]\u001b[A\n",
      " 67%|██████▋   | 37361/55894 [00:04<00:01, 9276.25it/s]\u001b[A\n",
      " 69%|██████▊   | 38303/55894 [00:04<00:01, 9317.22it/s]\u001b[A\n",
      " 70%|███████   | 39240/55894 [00:04<00:01, 9332.22it/s]\u001b[A\n",
      " 72%|███████▏  | 40184/55894 [00:04<00:01, 9361.82it/s]\u001b[A\n",
      " 74%|███████▎  | 41123/55894 [00:04<00:01, 9368.22it/s]\u001b[A\n",
      " 75%|███████▌  | 42085/55894 [00:04<00:01, 9439.69it/s]\u001b[A\n",
      " 77%|███████▋  | 43056/55894 [00:04<00:01, 9517.90it/s]\u001b[A\n",
      " 79%|███████▊  | 44009/55894 [00:04<00:01, 9515.01it/s]\u001b[A\n",
      " 80%|████████  | 44966/55894 [00:04<00:01, 9528.60it/s]\u001b[A\n",
      " 82%|████████▏ | 45923/55894 [00:04<00:01, 9540.37it/s]\u001b[A\n",
      " 84%|████████▍ | 46890/55894 [00:05<00:00, 9577.79it/s]\u001b[A\n",
      " 86%|████████▌ | 47851/55894 [00:05<00:00, 9586.77it/s]\u001b[A\n",
      " 87%|████████▋ | 48810/55894 [00:05<00:00, 9572.99it/s]\u001b[A\n",
      " 89%|████████▉ | 49768/55894 [00:05<00:00, 9423.78it/s]\u001b[A\n",
      " 91%|█████████ | 50711/55894 [00:05<00:00, 9389.27it/s]\u001b[A\n",
      " 92%|█████████▏| 51651/55894 [00:05<00:00, 9336.54it/s]\u001b[A\n",
      " 94%|█████████▍| 52606/55894 [00:05<00:00, 9396.72it/s]\u001b[A\n",
      " 96%|█████████▌| 53547/55894 [00:05<00:00, 9393.29it/s]\u001b[A\n",
      " 97%|█████████▋| 54487/55894 [00:05<00:00, 9368.74it/s]\u001b[A\n",
      " 99%|█████████▉| 55439/55894 [00:05<00:00, 9412.52it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab\n",
    "w_vec = vocab.Vectors('patent-100.vec',my_path)\n",
    "c_vec = vocab.Vectors('nasari_patents.vec',my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field.build_vocab(train, val, vectors=w_vec) #max_size=100000,\n",
    "conc_field.build_vocab(train, val, vectors=c_vec)\n",
    "label_field.build_vocab(train)\n",
    "#conc_field.vocab.itos\n",
    "#txt_field.vocab.vectors.shape, txt_field.vocab.vectors[txt_field.vocab.stoi['very']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "traindl, valdl = ttdata.BucketIterator.splits(datasets=(train, val), batch_sizes=(5,3), \n",
    "                                            sort_key=lambda x: (len(x.words),len(x.concepts)), \n",
    "                                            device=device, sort_within_batch=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self,dl, x_wfield, x_cfield, y_field):\n",
    "        self.dl, self.x_wfield, self.x_cfield, self.y_field = dl, x_wfield, x_cfield, y_field\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            xw = getattr(b, self.x_wfield)\n",
    "            xc = getattr(b, self.x_cfield)\n",
    "            y = getattr(b, self.y_field)\n",
    "            yield((xw, xc), y)\n",
    "train_batch_it = BatchGenerator(traindl, 'words', 'concepts','category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "SEED = 789 #123456\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "class ConcatPoolingGRU(nn.Module):\n",
    "    def __init__(self, wvocab_sz, wemb_dim,cvocab_sz, cemb_dim, n_hidden, n_out, wpre_vec, cpre_vec,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.wvocab_sz = wvocab_sz\n",
    "        self.cvocab_sz = cvocab_sz\n",
    "        self.wemb_dim = wemb_dim\n",
    "        self.cemb_dim = cemb_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        \n",
    "        self.wemb = nn.Embedding(self.wvocab_sz, self.wemb_dim)\n",
    "        self.wemb.weight.data.copy_(wpre_vec)\n",
    "        self.wemb.weight.requires_grad = False\n",
    "        self.cemb = nn.Embedding(self.cvocab_sz, self.cemb_dim)\n",
    "        self.cemb.weight.data.copy_(cpre_vec)\n",
    "        self.cemb.weight.requires_grad = False\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.wgru = nn.GRU(self.wemb_dim,self.n_hidden, bidirectional=bidirectional)\n",
    "        self.cgru = nn.GRU(self.cemb_dim,self.n_hidden, bidirectional=bidirectional)\n",
    "        self.lin1 = nn.Linear(300, self.n_hidden)\n",
    "        self.nlin1 = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        if bidirectional:\n",
    "            self.out = nn.Linear(self.n_hidden*2*2, self.n_out)\n",
    "        else:\n",
    "            self.out = nn.Linear(self.n_hidden*4, self.n_out)\n",
    "            \n",
    "    def forward(self, seq):\n",
    "#         bs = seq.size(1)\n",
    "        w_seq, c_seq = seq\n",
    "        w_seq,wl_seq = w_seq\n",
    "        wl_seq, _ = torch.sort(wl_seq, descending=True)\n",
    "#         print(wl_seq)\n",
    "        c_seq,cl_seq = c_seq\n",
    "        bs = w_seq.size(1)\n",
    "        self.hw = self.init_hidden(bs)\n",
    "        self.hc = self.init_hidden(bs)\n",
    "        \n",
    "        w_seq = w_seq.transpose(0,1)\n",
    "        c_seq = c_seq.transpose(0,1)\n",
    "        \n",
    "        wembs = self.wemb(w_seq)\n",
    "        wembs = wembs.transpose(0,1)\n",
    "        wembs = nn.utils.rnn.pack_padded_sequence(wembs, wl_seq)\n",
    "        \n",
    "        cembs = self.cemb(c_seq)\n",
    "#         cembs = cembs.transpose(0,1)\n",
    "#         cembs = nn.utils.rnn.pack_padded_sequence(cembs, torch.sort(cl_seq, descending=True)[0])\n",
    "        cembs = cembs.mean(dim=1)\n",
    "#         print(cembs.shape)\n",
    "        cembs = self.lin1(cembs)\n",
    "        cembs = self.drop(cembs)\n",
    "        cembs = self.nlin1(cembs)\n",
    "        \n",
    "        cembs = cembs.view(bs,-1)\n",
    "#         cembs = cembs.transpose(0,1)\n",
    "        wgru_out, self.hw = self.wgru(wembs, self.hw)\n",
    "        wgru_out, _ = nn.utils.rnn.pad_packed_sequence(wgru_out)\n",
    "#         print(self.hw.shape)\n",
    "#         cgru_out, self.hc = self.cgru(cembs, self.hc)\n",
    "#         cgru_out, _ = nn.utils.rnn.pad_packed_sequence(cgru_out)\n",
    "        \n",
    "        wavg_pool = nn.functional.adaptive_avg_pool1d(wgru_out.permute(1,2,0),1).view(bs, -1)\n",
    "        wmax_pool = nn.functional.adaptive_avg_pool1d(wgru_out.permute(1,2,0),1).view(bs,-1)\n",
    "        wmax_pool = self.drop(wmax_pool)\n",
    "        wmax_pool = self.nlin1(wmax_pool)\n",
    "        wavg_pool = self.drop(wavg_pool)\n",
    "        wavg_pool = self.nlin1(wavg_pool)\n",
    "#         cavg_pool = nn.functional.adaptive_avg_pool1d(cgru_out.permute(1,2,0),1).view(bs,-1)\n",
    "#         cmax_pool = nn.functional.adaptive_avg_pool1d(cgru_out.permute(1,2,0),1).view(bs,-1)\n",
    "        \n",
    "        outp = self.out(torch.cat([torch.squeeze(self.hw),wavg_pool,wmax_pool,cembs],dim=1))\n",
    "        return nn.functional.log_softmax(outp, dim=-1)\n",
    "        \n",
    "    def init_hidden(self, batch_sz):\n",
    "        if self.bidirectional:\n",
    "            return torch.zeros(2, batch_sz, self.n_hidden).to(device)\n",
    "        else:\n",
    "            return torch.zeros(1,batch_sz, self.n_hidden).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvocab_sz = len(txt_field.vocab)\n",
    "wemb_dim = 100\n",
    "cvocab_sz = len(conc_field.vocab)\n",
    "cemb_dim = 300\n",
    "\n",
    "n_hidden = 64\n",
    "n_out = len(label_field.vocab)\n",
    "\n",
    "traindl, valdl = data.BucketIterator.splits(datasets=(train, val), batch_sizes=(8,16), sort_key=lambda x:(len(x.words),len(x.concepts)), device=device, sort_within_batch=True,repeat=False)\n",
    "train_batch_it = BatchGenerator(traindl,'words','concepts','category')\n",
    "val_batch_it = BatchGenerator(valdl, 'words','concepts','category')\n",
    "m = ConcatPoolingGRU(wvocab_sz,wemb_dim,cvocab_sz,cemb_dim, n_hidden, n_out, train.fields['words'].vocab.vectors,train.fields['concepts'].vocab.vectors, bidirectional=False).to(device)\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-2)\n",
    "criterion = nn.NLLLoss()\n",
    "# fit model with ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.45 f1: 0.81\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.70 Avg loss: 0.92 f1: 0.63\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.86 Avg loss: 0.36 f1: 0.86\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.70 Avg loss: 0.94 f1: 0.59\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.85 Avg loss: 0.40 f1: 0.83\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.69 Avg loss: 1.04 f1: 0.62\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.82 Avg loss: 0.46 f1: 0.82\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.66 Avg loss: 1.05 f1: 0.54\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.83 Avg loss: 0.44 f1: 0.78\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.69 Avg loss: 0.97 f1: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7fb4ae350780>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Precision, Recall, MetricsLambda\n",
    "from ignite.handlers import ModelCheckpoint,  EarlyStopping\n",
    "# def process_function(engine, batch):\n",
    "#     m.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     x, y = batch.content, batch.label\n",
    "#     y_pred = m(x)\n",
    "#     loss = criterion(y_pred, y)\n",
    "#     loss.backward()\n",
    "#     opt.step()\n",
    "#     return loss.item()\n",
    "\n",
    "# def eval_function(engine, batch):\n",
    "#     m.eval()\n",
    "#     with torch.no_grad():\n",
    "#         x, y = batch.content, batch.label\n",
    "#         y_pred = m(x)\n",
    "#         return y_pred, y\n",
    "    \n",
    "# trainer = Engine(process_function)\n",
    "precision = Precision(average=False)\n",
    "recall = Recall(average=False)\n",
    "F1 = precision*recall*2/(precision+recall+1e-20)\n",
    "F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n",
    "trainer = create_supervised_trainer(m, opt, criterion)\n",
    "# train_evaluator = Engine(eval_function)\n",
    "evaluator = create_supervised_evaluator(m, metrics={'accuracy':Accuracy(),'nll': Loss(criterion), 'f1':F1})\n",
    "# validation_evaluator = Engine(eval_function)\n",
    "\n",
    "# RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_batch_it)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['nll'], metrics['f1']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_batch_it)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['nll'], metrics['f1']))\n",
    "\n",
    "trainer.run(train_batch_it, max_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7_torch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
